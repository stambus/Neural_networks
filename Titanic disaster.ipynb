{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(418, 11)\n"
                }, 
                {
                    "execution_count": 9, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(891, 12)\n"
                }, 
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "train_body = client_34618b67087348bc93a2e29e3a80b20d.get_object(Bucket='kaggle-donotdelete-pr-f8uklxjuxuvozp',Key='train.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(train_body, \"__iter__\"): train_body.__iter__ = types.MethodType( __iter__, train_body )\n\ntrain = pd.read_csv(train_body)\nprint(train.shape)\ntrain.head()"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "train['Age'].fillna((train['Age'].mean()), inplace=True)\ntrain.isna().sum()"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Pclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nSurvived    0\ndtype: int64\n(891, 7)\n"
                }
            ], 
            "source": "train = train[['Pclass','Sex','Age','SibSp','Parch','Fare','Survived']]\nprint(train.shape)"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/generic.py:6586: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self._update_inplace(new_data)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  app.launch_new_instance()\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 19, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0.2750</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.014151</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0.4750</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.139136</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0.3250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.015469</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0.4375</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.103644</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0.4375</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.015713</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "     Pclass  Sex     Age  SibSp  Parch      Fare\n0  1.000000    1  0.2750      1      0  0.014151\n1  0.333333    0  0.4750      1      0  0.139136\n2  1.000000    0  0.3250      0      0  0.015469\n3  0.333333    0  0.4375      1      0  0.103644\n4  1.000000    1  0.4375      0      0  0.015713"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "x_train = train[['Pclass','Sex','Age','SibSp','Parch','Fare']]\nx_train['Sex'].replace({'female':0, 'male':1}, inplace=True)\nx_train['Age'] = x_train['Age'] / np.max(x_train['Age'])\nx_train['Pclass'] = x_train['Pclass'] / np.max(x_train['Pclass'])\nx_train['Fare'] = x_train['Fare'] / np.max(x_train['Fare'])\nx_train.head()"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "test['Age'].fillna((test['Age'].mean()), inplace=True)"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  app.launch_new_instance()\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
                }, 
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0.453947</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.015282</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0.618421</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.013663</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0.666667</td>\n      <td>1</td>\n      <td>0.815789</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.018909</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0.355263</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.016908</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0.289474</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.023984</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   PassengerId    Pclass  Sex       Age  SibSp  Parch      Fare\n0          892  1.000000    1  0.453947      0      0  0.015282\n1          893  1.000000    0  0.618421      1      0  0.013663\n2          894  0.666667    1  0.815789      0      0  0.018909\n3          895  1.000000    1  0.355263      0      0  0.016908\n4          896  1.000000    0  0.289474      1      1  0.023984"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "x_test = test[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare']]\nx_test['Sex'].replace({'female':0, 'male':1}, inplace=True)\nx_test['Age'] = x_test['Age'] / np.max(x_test['Age'])\nx_test['Pclass'] = x_test['Pclass'] / np.max(x_test['Pclass'])\nx_test['Fare'] = x_test['Fare'] / np.max(x_test['Fare'])\nx_test.head()"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 23, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(891,)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_train = train['Survived']\ny_train.dropna(inplace=True)\ny_train.shape"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "n_cols = x_train.shape[1]"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define regression model\ndef regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(1, activation='relu'))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n    return model"
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
                }
            ], 
            "source": "# build the model\nour_model = regression_model()"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 623 samples, validate on 268 samples\nEpoch 1/100\n623/623 [==============================] - 3s 6ms/step - loss: 0.3158 - acc: 0.5859 - val_loss: 0.2624 - val_acc: 0.6045\nEpoch 2/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.2413 - acc: 0.6003 - val_loss: 0.2247 - val_acc: 0.6642\nEpoch 3/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.2042 - acc: 0.6854 - val_loss: 0.1887 - val_acc: 0.7425\nEpoch 4/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1833 - acc: 0.7833 - val_loss: 0.1705 - val_acc: 0.7873\nEpoch 5/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1725 - acc: 0.7929 - val_loss: 0.1607 - val_acc: 0.8060\nEpoch 6/100\n623/623 [==============================] - 3s 6ms/step - loss: 0.1657 - acc: 0.7961 - val_loss: 0.1535 - val_acc: 0.8097\nEpoch 7/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1600 - acc: 0.7929 - val_loss: 0.1497 - val_acc: 0.8097\nEpoch 8/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1597 - acc: 0.7978 - val_loss: 0.1454 - val_acc: 0.8022\nEpoch 9/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1549 - acc: 0.7978 - val_loss: 0.1401 - val_acc: 0.8060\nEpoch 10/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1542 - acc: 0.7978 - val_loss: 0.1404 - val_acc: 0.8022\nEpoch 11/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1536 - acc: 0.8026 - val_loss: 0.1363 - val_acc: 0.8097\nEpoch 12/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1490 - acc: 0.8026 - val_loss: 0.1349 - val_acc: 0.8022\nEpoch 13/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1478 - acc: 0.8058 - val_loss: 0.1333 - val_acc: 0.8097\nEpoch 14/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1476 - acc: 0.8010 - val_loss: 0.1317 - val_acc: 0.8097\nEpoch 15/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1455 - acc: 0.8042 - val_loss: 0.1304 - val_acc: 0.8097\nEpoch 16/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1444 - acc: 0.8026 - val_loss: 0.1304 - val_acc: 0.8134\nEpoch 17/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1464 - acc: 0.8042 - val_loss: 0.1317 - val_acc: 0.8097\nEpoch 18/100\n623/623 [==============================] - 4s 6ms/step - loss: 0.1437 - acc: 0.8042 - val_loss: 0.1301 - val_acc: 0.8172\nEpoch 19/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1414 - acc: 0.8058 - val_loss: 0.1309 - val_acc: 0.8246\nEpoch 20/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1437 - acc: 0.8074 - val_loss: 0.1358 - val_acc: 0.8172\nEpoch 21/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1440 - acc: 0.8138 - val_loss: 0.1300 - val_acc: 0.8134\nEpoch 22/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1400 - acc: 0.8154 - val_loss: 0.1280 - val_acc: 0.8284\nEpoch 23/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1394 - acc: 0.8154 - val_loss: 0.1277 - val_acc: 0.8172\nEpoch 24/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1388 - acc: 0.8138 - val_loss: 0.1283 - val_acc: 0.8134\nEpoch 25/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1405 - acc: 0.8186 - val_loss: 0.1295 - val_acc: 0.8134\nEpoch 26/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1388 - acc: 0.8170 - val_loss: 0.1291 - val_acc: 0.8246\nEpoch 27/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1391 - acc: 0.8186 - val_loss: 0.1273 - val_acc: 0.8209\nEpoch 28/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1371 - acc: 0.8154 - val_loss: 0.1287 - val_acc: 0.8209\nEpoch 29/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1386 - acc: 0.8090 - val_loss: 0.1278 - val_acc: 0.8172\nEpoch 30/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1368 - acc: 0.8154 - val_loss: 0.1283 - val_acc: 0.8209\nEpoch 31/100\n623/623 [==============================] - 4s 7ms/step - loss: 0.1367 - acc: 0.8154 - val_loss: 0.1273 - val_acc: 0.8172\nEpoch 32/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1363 - acc: 0.8186 - val_loss: 0.1269 - val_acc: 0.8284\nEpoch 33/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1352 - acc: 0.8186 - val_loss: 0.1294 - val_acc: 0.8209\nEpoch 34/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1375 - acc: 0.8154 - val_loss: 0.1280 - val_acc: 0.8172\nEpoch 35/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1348 - acc: 0.8234 - val_loss: 0.1306 - val_acc: 0.8134\nEpoch 36/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1348 - acc: 0.8202 - val_loss: 0.1299 - val_acc: 0.8209\nEpoch 37/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1338 - acc: 0.8186 - val_loss: 0.1279 - val_acc: 0.8209\nEpoch 38/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1347 - acc: 0.8218 - val_loss: 0.1282 - val_acc: 0.8209\nEpoch 39/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1336 - acc: 0.8218 - val_loss: 0.1310 - val_acc: 0.8246\nEpoch 40/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1333 - acc: 0.8154 - val_loss: 0.1285 - val_acc: 0.8209\nEpoch 41/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1327 - acc: 0.8186 - val_loss: 0.1310 - val_acc: 0.8209\nEpoch 42/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1330 - acc: 0.8202 - val_loss: 0.1298 - val_acc: 0.8246\nEpoch 43/100\n623/623 [==============================] - 5s 7ms/step - loss: 0.1335 - acc: 0.8154 - val_loss: 0.1301 - val_acc: 0.8209\nEpoch 44/100\n623/623 [==============================] - 3s 5ms/step - loss: 0.1335 - acc: 0.8250 - val_loss: 0.1314 - val_acc: 0.8246\nEpoch 45/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1343 - acc: 0.8202 - val_loss: 0.1327 - val_acc: 0.8209\nEpoch 46/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1333 - acc: 0.8218 - val_loss: 0.1295 - val_acc: 0.8246\nEpoch 47/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1337 - acc: 0.8186 - val_loss: 0.1323 - val_acc: 0.8209\nEpoch 48/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1330 - acc: 0.8234 - val_loss: 0.1318 - val_acc: 0.8209\nEpoch 49/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1313 - acc: 0.8186 - val_loss: 0.1309 - val_acc: 0.8246\nEpoch 50/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1312 - acc: 0.8234 - val_loss: 0.1283 - val_acc: 0.8246\nEpoch 51/100\n623/623 [==============================] - 4s 6ms/step - loss: 0.1325 - acc: 0.8186 - val_loss: 0.1312 - val_acc: 0.8134\nEpoch 52/100\n623/623 [==============================] - 3s 6ms/step - loss: 0.1329 - acc: 0.8266 - val_loss: 0.1291 - val_acc: 0.8246\nEpoch 53/100\n623/623 [==============================] - 4s 6ms/step - loss: 0.1305 - acc: 0.8218 - val_loss: 0.1291 - val_acc: 0.8209\nEpoch 54/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1307 - acc: 0.8218 - val_loss: 0.1330 - val_acc: 0.8209\nEpoch 55/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1342 - acc: 0.8154 - val_loss: 0.1350 - val_acc: 0.8060\nEpoch 56/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1311 - acc: 0.8202 - val_loss: 0.1328 - val_acc: 0.8172\nEpoch 57/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1318 - acc: 0.8299 - val_loss: 0.1296 - val_acc: 0.8246\nEpoch 58/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1306 - acc: 0.8283 - val_loss: 0.1300 - val_acc: 0.8284\nEpoch 59/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1325 - acc: 0.8202 - val_loss: 0.1288 - val_acc: 0.8321\nEpoch 60/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1290 - acc: 0.8283 - val_loss: 0.1308 - val_acc: 0.8209\nEpoch 61/100\n623/623 [==============================] - 3s 5ms/step - loss: 0.1298 - acc: 0.8250 - val_loss: 0.1283 - val_acc: 0.8321\nEpoch 62/100\n623/623 [==============================] - 3s 5ms/step - loss: 0.1299 - acc: 0.8283 - val_loss: 0.1294 - val_acc: 0.8246\nEpoch 63/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1327 - acc: 0.8234 - val_loss: 0.1317 - val_acc: 0.8284\nEpoch 64/100\n623/623 [==============================] - 2s 4ms/step - loss: 0.1306 - acc: 0.8202 - val_loss: 0.1393 - val_acc: 0.7910\nEpoch 65/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1307 - acc: 0.8202 - val_loss: 0.1311 - val_acc: 0.8246\nEpoch 66/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1287 - acc: 0.8202 - val_loss: 0.1301 - val_acc: 0.8246\nEpoch 67/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1305 - acc: 0.8250 - val_loss: 0.1298 - val_acc: 0.8246\nEpoch 68/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1306 - acc: 0.8299 - val_loss: 0.1355 - val_acc: 0.7985\nEpoch 69/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1285 - acc: 0.8250 - val_loss: 0.1294 - val_acc: 0.8209\nEpoch 70/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1292 - acc: 0.8218 - val_loss: 0.1295 - val_acc: 0.8284\nEpoch 71/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1284 - acc: 0.8266 - val_loss: 0.1302 - val_acc: 0.8246\nEpoch 72/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1304 - acc: 0.8266 - val_loss: 0.1311 - val_acc: 0.8246\nEpoch 73/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1274 - acc: 0.8283 - val_loss: 0.1355 - val_acc: 0.7985\nEpoch 74/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1297 - acc: 0.8090 - val_loss: 0.1304 - val_acc: 0.8209\nEpoch 75/100\n623/623 [==============================] - 3s 5ms/step - loss: 0.1294 - acc: 0.8202 - val_loss: 0.1307 - val_acc: 0.8284\nEpoch 76/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1278 - acc: 0.8266 - val_loss: 0.1317 - val_acc: 0.8097\nEpoch 77/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1298 - acc: 0.8283 - val_loss: 0.1315 - val_acc: 0.8246\nEpoch 78/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1282 - acc: 0.8234 - val_loss: 0.1279 - val_acc: 0.8246\nEpoch 79/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1292 - acc: 0.8202 - val_loss: 0.1299 - val_acc: 0.8172\nEpoch 80/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1288 - acc: 0.8315 - val_loss: 0.1290 - val_acc: 0.8209\nEpoch 81/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1291 - acc: 0.8202 - val_loss: 0.1319 - val_acc: 0.8172\nEpoch 82/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1303 - acc: 0.8218 - val_loss: 0.1294 - val_acc: 0.8284\nEpoch 83/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1287 - acc: 0.8266 - val_loss: 0.1317 - val_acc: 0.8246\nEpoch 84/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1284 - acc: 0.8331 - val_loss: 0.1285 - val_acc: 0.8321\nEpoch 85/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1281 - acc: 0.8331 - val_loss: 0.1279 - val_acc: 0.8246\nEpoch 86/100\n623/623 [==============================] - 4s 6ms/step - loss: 0.1265 - acc: 0.8234 - val_loss: 0.1304 - val_acc: 0.8246\nEpoch 87/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1272 - acc: 0.8266 - val_loss: 0.1288 - val_acc: 0.8284\nEpoch 88/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1286 - acc: 0.8299 - val_loss: 0.1331 - val_acc: 0.8134\nEpoch 89/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1295 - acc: 0.8186 - val_loss: 0.1307 - val_acc: 0.8172\nEpoch 90/100\n623/623 [==============================] - 2s 3ms/step - loss: 0.1273 - acc: 0.8315 - val_loss: 0.1297 - val_acc: 0.8284\nEpoch 91/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1263 - acc: 0.8218 - val_loss: 0.1320 - val_acc: 0.8022\nEpoch 92/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1265 - acc: 0.8266 - val_loss: 0.1299 - val_acc: 0.8246\nEpoch 93/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1262 - acc: 0.8266 - val_loss: 0.1298 - val_acc: 0.8097\nEpoch 94/100\n623/623 [==============================] - 1s 2ms/step - loss: 0.1254 - acc: 0.8250 - val_loss: 0.1323 - val_acc: 0.8209\nEpoch 95/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1286 - acc: 0.8283 - val_loss: 0.1404 - val_acc: 0.7948\nEpoch 96/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1269 - acc: 0.8218 - val_loss: 0.1314 - val_acc: 0.8134\nEpoch 97/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1266 - acc: 0.8250 - val_loss: 0.1315 - val_acc: 0.8097\nEpoch 98/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1260 - acc: 0.8266 - val_loss: 0.1293 - val_acc: 0.8246\nEpoch 99/100\n623/623 [==============================] - 1s 1ms/step - loss: 0.1242 - acc: 0.8266 - val_loss: 0.1310 - val_acc: 0.8097\nEpoch 100/100\n623/623 [==============================] - 5s 7ms/step - loss: 0.1257 - acc: 0.8283 - val_loss: 0.1311 - val_acc: 0.8172\n"
                }, 
                {
                    "execution_count": 27, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f95a87f7208>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# fit the model\nour_model.fit(x_train, y_train, validation_split=0.3, epochs=50)"
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 28, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 0.14171845],\n       [ 0.5500559 ],\n       [ 0.08277646],\n       [ 0.14935729],\n       [ 0.685156  ],\n       [ 0.17811206],\n       [ 0.63855356],\n       [ 0.50888556],\n       [ 0.63324225],\n       [ 0.10899872],\n       [ 0.14630684],\n       [ 0.28424364],\n       [ 0.992125  ],\n       [ 0.04684092],\n       [ 0.99087286],\n       [ 0.8611499 ],\n       [ 0.16418648],\n       [ 0.15694395],\n       [ 0.52026147],\n       [ 0.66291815],\n       [ 0.29622966],\n       [ 0.45975915],\n       [ 0.9838284 ],\n       [ 0.5439312 ],\n       [ 0.35666957],\n       [-0.        ],\n       [ 1.1286062 ],\n       [ 0.15529934],\n       [ 0.34891182],\n       [ 0.02660471],\n       [ 0.05602117],\n       [ 0.15765992],\n       [ 0.6267024 ],\n       [ 0.63990796],\n       [ 0.4021491 ],\n       [ 0.16357544],\n       [ 0.63950694],\n       [ 0.63393295],\n       [ 0.1509628 ],\n       [ 0.10778541],\n       [-0.        ],\n       [ 0.45310432],\n       [ 0.13484949],\n       [ 0.91414845],\n       [ 0.98689795],\n       [ 0.1520674 ],\n       [ 0.28948617],\n       [ 0.14640906],\n       [ 0.82466704],\n       [ 0.60016835],\n       [ 0.447793  ],\n       [ 0.15262243],\n       [ 0.69956374],\n       [ 0.8678772 ],\n       [ 0.14738476],\n       [-0.        ],\n       [ 0.1411236 ],\n       [ 0.15226018],\n       [ 0.04064862],\n       [ 1.0206655 ],\n       [ 0.16841993],\n       [ 0.15153256],\n       [ 0.16494071],\n       [ 0.6303315 ],\n       [ 0.6368365 ],\n       [ 0.92425144],\n       [ 0.6335304 ],\n       [ 0.23927873],\n       [ 0.44570246],\n       [ 0.2592048 ],\n       [ 0.6288531 ],\n       [ 0.15647352],\n       [ 0.6375487 ],\n       [ 0.45066443],\n       [ 1.014538  ],\n       [-0.        ],\n       [ 0.14619863],\n       [ 0.9664832 ],\n       [ 0.15108067],\n       [ 0.6288531 ],\n       [ 0.6045324 ],\n       [ 0.4286867 ],\n       [ 0.24657992],\n       [ 0.14630684],\n       [ 0.15424976],\n       [ 0.04128694],\n       [ 0.6342973 ],\n       [ 0.6336062 ],\n       [ 0.63910043],\n       [ 0.9676721 ],\n       [ 0.5169259 ],\n       [ 0.14639148],\n       [ 0.9572496 ],\n       [ 0.14619863],\n       [ 0.45758277],\n       [ 0.15215796],\n       [ 0.96488255],\n       [ 0.14768162],\n       [ 0.6357578 ],\n       [ 0.1432083 ],\n       [ 0.9907648 ],\n       [ 0.13030204],\n       [ 0.14640906],\n       [ 0.15107608],\n       [ 0.7241074 ],\n       [ 0.13853908],\n       [ 0.15652609],\n       [ 0.14640906],\n       [ 0.14573404],\n       [ 0.18296656],\n       [ 0.16752523],\n       [ 0.63914   ],\n       [ 0.93535167],\n       [ 0.6335707 ],\n       [ 1.114675  ],\n       [ 0.18949565],\n       [ 0.14732951],\n       [ 0.82144594],\n       [ 0.26445967],\n       [ 0.86493117],\n       [ 0.86081046],\n       [ 0.04450095],\n       [ 0.9911646 ],\n       [ 0.14925146],\n       [ 0.14640906],\n       [ 0.625986  ],\n       [ 0.15544719],\n       [ 0.6441235 ],\n       [ 0.16639781],\n       [ 0.15307614],\n       [ 0.14430472],\n       [ 0.19000897],\n       [ 0.52718735],\n       [ 0.04513567],\n       [ 0.12164006],\n       [ 0.15321344],\n       [ 0.15091357],\n       [ 0.15686673],\n       [ 0.6280149 ],\n       [-0.        ],\n       [ 0.12627867],\n       [ 0.9971243 ],\n       [-0.        ],\n       [ 0.13849068],\n       [ 0.34200773],\n       [ 0.04083856],\n       [ 0.36691892],\n       [ 0.15526894],\n       [ 0.45310432],\n       [ 0.4439066 ],\n       [ 1.1038064 ],\n       [ 0.14630684],\n       [        nan],\n       [ 0.60634446],\n       [ 0.13539734],\n       [ 0.15342677],\n       [ 1.0096495 ],\n       [ 0.62781566],\n       [ 0.3420077 ],\n       [ 0.690264  ],\n       [ 0.63907784],\n       [ 0.5859058 ],\n       [ 0.90905905],\n       [ 0.14693508],\n       [ 0.16890755],\n       [ 0.6560083 ],\n       [ 0.21072486],\n       [ 0.42775816],\n       [ 0.9839118 ],\n       [ 0.6315909 ],\n       [ 0.14654931],\n       [ 0.15036541],\n       [ 0.13021293],\n       [ 0.14677429],\n       [-0.        ],\n       [ 0.9759439 ],\n       [ 0.92329514],\n       [ 0.3005524 ],\n       [ 0.73391575],\n       [ 0.9006403 ],\n       [ 0.15108067],\n       [ 0.5520086 ],\n       [ 0.9756845 ],\n       [ 0.14640906],\n       [ 1.0508773 ],\n       [ 0.1693902 ],\n       [ 0.90196514],\n       [ 0.13843247],\n       [-0.        ],\n       [ 0.17141728],\n       [ 0.09974919],\n       [ 0.45497698],\n       [ 0.4980204 ],\n       [ 0.08633735],\n       [ 0.8162693 ],\n       [ 0.1433456 ],\n       [ 0.8696724 ],\n       [ 0.63348424],\n       [ 0.16561496],\n       [ 0.63959163],\n       [ 0.64960045],\n       [ 0.81399435],\n       [ 0.44723204],\n       [ 0.9362448 ],\n       [ 0.1616275 ],\n       [ 0.45585644],\n       [ 0.64574564],\n       [ 0.16362125],\n       [ 0.9624805 ],\n       [ 0.15208781],\n       [ 0.13415334],\n       [ 0.14689997],\n       [ 0.11644963],\n       [ 0.8402382 ],\n       [ 0.23761907],\n       [ 0.30664846],\n       [ 0.63927555],\n       [ 0.3161634 ],\n       [ 1.1122106 ],\n       [ 0.14619863],\n       [ 0.84564745],\n       [ 0.15636542],\n       [ 0.89687896],\n       [ 0.15654364],\n       [ 0.81178874],\n       [ 0.6508391 ],\n       [ 0.15435085],\n       [ 0.63910043],\n       [ 0.12833878],\n       [ 0.16779953],\n       [ 0.13774136],\n       [ 1.035918  ],\n       [ 0.15973195],\n       [ 0.14631844],\n       [ 0.3543346 ],\n       [ 0.15788722],\n       [ 0.27837378],\n       [ 0.1583088 ],\n       [ 0.87558633],\n       [ 1.0190693 ],\n       [ 0.8074806 ],\n       [ 0.77182376],\n       [ 0.41594625],\n       [ 0.14631262],\n       [ 0.17138556],\n       [ 0.34158432],\n       [ 0.9094039 ],\n       [ 0.24621353],\n       [ 0.86493117],\n       [ 0.5402809 ],\n       [ 1.002215  ],\n       [ 0.15783986],\n       [ 0.40355122],\n       [ 0.15218192],\n       [ 0.1427396 ],\n       [ 0.14654931],\n       [ 0.14640906],\n       [ 0.1486904 ],\n       [ 0.8945039 ],\n       [ 0.15655819],\n       [-0.        ],\n       [ 0.1565027 ],\n       [ 0.8996188 ],\n       [ 0.8236897 ],\n       [ 0.1514507 ],\n       [ 0.14630684],\n       [ 0.53481615],\n       [ 0.14654931],\n       [ 0.63950694],\n       [ 0.16777918],\n       [ 0.18719871],\n       [ 0.14640906],\n       [ 1.0295525 ],\n       [ 0.54228896],\n       [ 0.14677721],\n       [ 0.8506574 ],\n       [ 0.15564615],\n       [ 0.07963771],\n       [ 0.11717992],\n       [ 0.16760878],\n       [ 0.6286382 ],\n       [ 0.7006609 ],\n       [ 0.63910043],\n       [ 0.77375317],\n       [ 0.8146634 ],\n       [ 0.14073387],\n       [ 0.14675972],\n       [ 0.4382781 ],\n       [ 0.14677429],\n       [ 0.14619863],\n       [ 0.40867096],\n       [ 0.63763344],\n       [ 0.14677429],\n       [ 0.39893574],\n       [ 0.13913807],\n       [ 0.15099138],\n       [ 0.9704939 ],\n       [ 0.02660471],\n       [ 0.3888201 ],\n       [ 0.14773136],\n       [ 0.1444976 ],\n       [ 0.14813656],\n       [-0.        ],\n       [ 0.15264657],\n       [ 0.63910043],\n       [ 1.0217594 ],\n       [ 0.555857  ],\n       [ 0.54110396],\n       [ 0.3861887 ],\n       [ 0.5576329 ],\n       [ 0.16417816],\n       [ 0.15584758],\n       [ 0.14653182],\n       [ 0.64855707],\n       [ 0.8927653 ],\n       [ 0.6328567 ],\n       [ 0.35447562],\n       [ 0.18483531],\n       [ 0.14992416],\n       [ 0.16979825],\n       [ 0.15107608],\n       [ 0.15255535],\n       [ 0.15686673],\n       [ 0.45072466],\n       [ 1.0140696 ],\n       [ 0.15487385],\n       [ 0.7274658 ],\n       [ 0.18096656],\n       [ 0.12285092],\n       [ 0.16683544],\n       [ 0.752709  ],\n       [ 0.382007  ],\n       [ 0.14677721],\n       [ 0.70466995],\n       [ 0.14989498],\n       [ 0.45521477],\n       [ 0.15212306],\n       [ 0.0495845 ],\n       [ 0.13858753],\n       [ 0.14677429],\n       [ 0.1947203 ],\n       [ 0.14463487],\n       [ 0.07448428],\n       [ 0.7374896 ],\n       [ 0.18627709],\n       [ 0.63221085],\n       [ 0.15686673],\n       [ 0.6492572 ],\n       [ 0.16030079],\n       [ 0.92528737],\n       [ 1.1049417 ],\n       [ 0.1616275 ],\n       [ 0.1139429 ],\n       [ 0.08706605],\n       [ 0.901589  ],\n       [ 0.23402533],\n       [ 0.9795861 ],\n       [ 0.14631844],\n       [ 0.14640906],\n       [ 0.54176176],\n       [-0.        ],\n       [ 0.8706478 ],\n       [ 0.92528737],\n       [ 0.14935729],\n       [ 0.9771478 ],\n       [ 0.4943477 ],\n       [ 0.0412853 ],\n       [ 0.6571195 ],\n       [ 1.1070844 ],\n       [ 0.15009424],\n       [ 0.20845234],\n       [ 0.9925488 ],\n       [ 0.29758826],\n       [ 0.1613783 ],\n       [ 1.0728465 ],\n       [ 1.0273726 ],\n       [ 0.55328137],\n       [ 0.16893148],\n       [ 0.13611403],\n       [ 0.21518224],\n       [ 0.14640906],\n       [ 0.151003  ],\n       [ 0.6482456 ],\n       [ 0.5068336 ],\n       [ 0.15119603],\n       [ 0.7807361 ],\n       [ 0.15326896],\n       [ 0.10388192],\n       [ 0.15657577],\n       [ 0.14720234],\n       [ 0.23268002],\n       [ 1.1015362 ],\n       [ 0.60576963],\n       [ 0.15443659],\n       [-0.        ],\n       [ 0.9790867 ],\n       [ 0.15363723],\n       [ 1.0767215 ],\n       [ 0.15546185],\n       [ 0.14562327],\n       [ 1.003404  ],\n       [ 0.08268446],\n       [ 1.1314434 ],\n       [ 0.40203103],\n       [ 0.32724988],\n       [ 0.17090182],\n       [ 0.18267183],\n       [ 0.3333829 ],\n       [ 0.6390609 ],\n       [ 0.81282336],\n       [ 0.63910043],\n       [ 1.0076202 ],\n       [ 0.63591397],\n       [ 0.14619863],\n       [ 0.9402112 ],\n       [ 0.13839445],\n       [ 0.14619869],\n       [ 0.17650595]], dtype=float32)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "y_predictions = our_model.predict(x_test[['Pclass','Sex','Age','SibSp','Parch','Fare']], verbose=0)\ny_predictions"
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pred_survived = {}\nfor pred in zip(y_predictions, x_test['PassengerId']):\n    if pred[0] > 0.7:\n        pred_survived[pred[1]] = 1\n    else:\n        pred_survived[pred[1]] = 0"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "final_data = pd.DataFrame(list(pred_survived.items()),columns=['PassengerId','Survived'])"
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "final_data.to_csv(\"predictions.csv\")"
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 32, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<a download=\"predictions_zyba.csv\" href=\"data:text/csv;base64,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\" target=\"_blank\">Download CSV file</a>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import base64\nfrom IPython.display import HTML\n\ndef create_download_link( df, title = \"Download CSV file\", filename = \"predictions_zyba.csv\"):\n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(final_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}